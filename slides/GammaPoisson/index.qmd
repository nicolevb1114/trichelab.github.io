---
format: 
  live-revealjs:
    margin: 0.05
    theme: default
    smaller: true
    slide-number: true
    html-math-method: mathjax
    include-before: [ '<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {enableAssistiveMml: false}});</script>']
    footer: "[Source code](https://github.com/trichelab/trichelab.github.io/blob/gh-pages/slides/GammaPoisson/index.qmd)"
engine: knitr
title: "Gamma-Poisson derivation and sampling"
author: "Tim Triche, Jr."
institute: "Van Andel Institute"
webr:
  packages: 
    - datasets
    - ggplot2
    - ggbeeswarm
execute: 
  warning: false
---
{{< include ./_extensions/r-wasm/live/_knitr.qmd >}}


## The Poisson distribution

Suppose we have rare events that occur at varying times but at a steady rate. 

A classic example is radioactive decay. At any instant, I can't tell you if a 
particle will be detected. But if you tell me the isotopic half-life, I can 
guess how many events you'll see in a day, year, or century. If the intensity
of decay is $\lambda$, we can reason about its emissions $X$.

We say $X \sim Pois(\lambda)$: "$X$ is Poisson with intensity $\lambda$".

$$
\begin{align}
E\left[X\right] &= \lambda \\
Var\left[X\right] &= \lambda \\
Pr(X=k|\lambda) &= \frac{\lambda^{k}}{k!}e^{-\lambda}
\end{align}
$$

---



## The exponential distribution

Suppose instead of _number_ of events, $X$, we track _time_ between events, $Y$.

Then $Y \sim Exp(\lambda)$: "$Y$ is exponential with intensity $\lambda$".

$$
E\left[Y\right] = \frac{1}{\lambda}
$$

The probability of $k$ events per observation $X$ is 
$Pr(\sum^{k}_{i=1}Y_i \leq 1)$:

$$
\begin{align}
Pr(0|\lambda) &= e^{-\lambda} \\
Pr(1|\lambda) &= \lambda e^{-\lambda} \\
Pr(2|\lambda) &= \frac{\lambda^2}{2!} e^{-\lambda} \\
... \\
Pr(k|\lambda) &= \frac{\lambda^k}{k!} e^{-\lambda}
\end{align}
$$

---



## Poisson / exponential demo

If the probability of an event per unit observation $\lambda = \frac{1}{10}$, 
the mean number of observations between events will be $\frac{1}{\lambda} = 10$.

```{webr}
n = 1000
lambda = 0.1
Y = rexp(n=n, rate=lambda)
mean(Y) - (1 / lambda) # small number
hist(Y)
```

---



## The binomial distribution

Suppose I don't care how many times an event happens, so much as _whether_ it 
happens to an individual. For example, whether someone dies, or is admitted to 
a UC Berkeley graduate program. We might want to model the importance of factors
to the outcome. One way to do this is with a binomial random variable $X$, where
the number of individuals who could experience the event is $n$, the probability
of experiencing the event is $p$, and we say $X \sim Bin(n, p)$. Then

$$
\begin{align}
Pr(X = k | n, p) &= \binom{n}{k} p^{k} \left( 1 - p \right)^{n-k} \\
\binom{n}{k} &= \frac{n!}{k! \left( n - k \right)!} \\
E\left[X\right] &= np \\
Var\left[X\right] &= np(1-p)
\end{align}
$$

If we model the probability $p$ of the event and use the _logistic_ function,
$\text{logit}(p) = log\frac{p}{1-p}$, we can perform _logistic regression_. 
Since $\text{logit}(p)$ can potentially be infinite, we can't perform a least-
squares fit the way we might for a linear model. But we can finesse this by
maximizing the likelihood (joint probability of seeing the observed data.

In the next slide we will see an example. For more details on maximum likelihood
and estimation of logistic models, [see this notebook](https://rpubs.com/ttriche/1011627).

---



### Logistic regression, part 1

Let's model the importance of sex in graduate admissions at Berkeley.
The `UCBAdmissions` data is included with R, in the `datasets` library.
(Need to modify this a bit to reflect the use of Freq rather than 0/1).

```{webr}
class(UCBAdmissions)
berk.data = as.data.frame(UCBAdmissions)
berk.data$Gender = relevel(berk.data$Gender, ref='Female')
berk.data$Dept = relevel(berk.data$Dept, ref='F')
berk.data$Outcome = with(berk.data, ifelse(Admit == "Admitted", 1, 0))
berk.fit = glm(Outcome ~ Gender + Dept, family=binomial(), data=berk.data)

```



---

## The Gamma distribution

Suppose we have $j$ exponentially distributed processes $Y_j \sim Exp(\lambda)$.

If $Z = \sum^{j}_{i=1} Y_j$, we can model the sum as $Z \sim Gamma(j, \lambda)$:

$$
\begin{align}
E\left[Z\right] &= \sum^{j}_{i=1} E\left[Y_j\right] = \frac{j}{\lambda} \\
Var\left[Z\right] &= \sum^{j}_{i=1} Var\left[Y_j\right] = \frac{j}{\lambda^2}\\
Pr(Z=z|j,\lambda) &= \frac{z^{j-1}e^{-z/\lambda}}{\lambda^j\Gamma(j)}, 
                     \text{where}\ \Gamma(n) = (n - 1)!
\end{align}
$$

---



## Gamma-Poisson background

Now we have the pieces to reconstruct a Poisson process across discrete samples.
We can reason about how variable $\lambda$ really is, both within and across 
samples, using a model that captures the sampling distribution of $\lambda$.

Suppose we look at inherited genetic variants in the general population; in a 
disease; and in a specific type or age group of disease. We might wonder whether
the rates of inherited genetic variants (of any sort!) are in each group, and 
we might wonder how strong the evidence is for differences between groups. But
if the disease is rare, we know that our estimate of $\lambda$ cannot be as 
precise as it would be if the disease was common, because we simply don't have 
as many observations. The Gamma-Poisson distribution helps us represent this 
inherent imprecision in our simulations and reason a

--- 



## Gamma-Poisson: simple case

Let's make our examples concrete by looking at germline genetic variants in 
an unselected control population, versus genetic variants in leukemia patients.
We will assume that clinically relevant genetic variants are somewhat rare, but
previous studies have confirmed that at least 5% of leukemia patients harbor 
inherited genetic variants which are rare in the general population. 

--- 



## Gamma-Poisson: more uses

Recall that one type of Gamma distribution is the sum of exponential processes.

A statistical model for graph traversal is the exponential random graph model, 
or Erdos-Renyi model, where the number of edges (connections) from any given
node (such as a gene, or a protein-protein interaction) is exponential. 

Since the sum of traversal times for disconnected graph components is a sum of
exponential processes under this random graph model, we can test the hypothesis
that the intensity of emissions ("hops" before hitting a gene variant, whether 
inherited or acquired) is the same across disease subtypes, and we can do this 
with an amended graph that reflects any protein-protein fusions in a patient:

---



## Gamma-Poisson: even more

(overdispersed loglinear models)

